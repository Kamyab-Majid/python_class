{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Practice Session\n",
    "\n",
    "> Covering Data Types, Functions, and IO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Engine (TF-IDF)\n",
    "\n",
    "> **TF-IDF** stands for “Term Frequency — Inverse Document Frequency”. This is a technique to quantify a word in documents, we generally compute a weight to each word which signifies the importance of the word in the document and corpus.\n",
    "\n",
    "If i give you a sentence for example _“This building is so tall”_. Its easy for us to understand the sentence as we know the semantics of the words and the sentence. But how will the computer understand this sentence? The computer can understand any data only in the form of numerical value. So, for this reason we vectorize all of the text so that the computer can understand the text better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By vectorizing the documents we can further perform multiple tasks such as finding the relevant documents, ranking, clustering and so on. This is the same thing that happens when you perform a google search. The web pages are called documents and the search text with which you search is called a query. google maintains a fixed representation for all of the documents. When you search with a query, google will find the relevance of the query with all of the documents, ranks them in the order of relevance and shows you the top k documents, all of this process is done using the vectorized form of query and documents. Although Googles algorithms are highly sophisticated and optimized, this is their underlying structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terminology\n",
    "- **t**: term (word)\n",
    "- **d**: document (set of words)\n",
    "- **N**: count of corpus\n",
    "- **corpus**: the total document set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step #1: Read Files\n",
    "\n",
    "> 1. Read the `data/files_path.txt` which contains all the documents you have to read.\n",
    "> 2. Read the files listed in `data/files_path.txt` and create a dictionary where keys are file names and values are file contents.\n",
    "\n",
    "```python\n",
    "docs = {\n",
    "    \"file_1\": \"content_1\",\n",
    "    \"file_2\": \"content_2\",\n",
    "    ...\n",
    "} \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/result.json\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step #2: Extract Unique Words in all Documents\n",
    "\n",
    "> Create a set of all words (`vocab`) and print the number of unique words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of messages in data\n",
    "len(data['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we store unique words in a set\n",
    "vocab = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in data['messages']:\n",
    "    \n",
    "    if not msg['text']:\n",
    "        continue\n",
    "    \n",
    "    if type(msg['text']) == list:\n",
    "        # TODO: add text content where there is a link, so far I'm ignoring messages that have link.\n",
    "        continue\n",
    "    \n",
    "    words = msg['text'].split()\n",
    "    vocab.update(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step #3: Extract Number of Words in each Document\n",
    "\n",
    "> 1. Extract words in each document by creating a dictionary named `tf_dict` where keys are document names and values are another dictionary.\n",
    "> 2. In the nested dictionary, keys are words and values are the corresponding word frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# term frequency (tf) dictionary\n",
    "tf_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in data['messages']:\n",
    "    \n",
    "    # ignoring messages that have no content\n",
    "    if not msg['text']:\n",
    "        continue\n",
    "    \n",
    "    if type(msg['text']) == list:\n",
    "        # TODO: add text content where there is a link, so far I'm ignoring messages that have link.\n",
    "        continue\n",
    "    \n",
    "    # tokenizing words\n",
    "    words = msg['text'].split()\n",
    "    \n",
    "    sender = msg['from']\n",
    "    # initializing an unseen sender with empty dict\n",
    "    if sender not in tf_dict:\n",
    "        tf_dict[sender] = {}\n",
    "    \n",
    "    # counting words for each sender\n",
    "    for word in words:\n",
    "        if word in tf_dict[sender]:\n",
    "            tf_dict[sender][word] += 1\n",
    "        else:\n",
    "            tf_dict[sender][word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fatemeh Modarres': {'سلام': 1,\n",
       "  'ب': 2,\n",
       "  'همگی،': 1,\n",
       "  'علی،': 1,\n",
       "  'امشب': 1,\n",
       "  'کلاس': 1,\n",
       "  'رفع': 1,\n",
       "  'اشکال': 1,\n",
       "  'چه': 1,\n",
       "  'ساعتی': 1,\n",
       "  'هست؟': 1,\n",
       "  'اوکی': 1,\n",
       "  'مرسیییی': 1,\n",
       "  '👌': 3,\n",
       "  'یعنی': 3,\n",
       "  'در': 1,\n",
       "  'اینده': 1,\n",
       "  'نزدیک،': 1,\n",
       "  'میشه': 2,\n",
       "  'یه': 2,\n",
       "  'ربات': 2,\n",
       "  'ساخت': 1,\n",
       "  'و': 6,\n",
       "  'دقیقا': 1,\n",
       "  'همون': 1,\n",
       "  'بینایی': 1,\n",
       "  'رو': 4,\n",
       "  'بهش': 1,\n",
       "  'منتقل': 1,\n",
       "  'کرد،': 1,\n",
       "  'احتمالا': 1,\n",
       "  'همین': 1,\n",
       "  'کانسپت': 1,\n",
       "  'برای': 1,\n",
       "  'حس': 1,\n",
       "  'شنوایی': 1,\n",
       "  'بویایی': 1,\n",
       "  '....': 1,\n",
       "  'کم': 2,\n",
       "  'استخراج': 1,\n",
       "  'اثبات': 1,\n",
       "  'بعدش': 1,\n",
       "  'اون': 1,\n",
       "  'انتقال': 1,\n",
       "  'دهنده': 1,\n",
       "  'های': 2,\n",
       "  'عصبی': 1,\n",
       "  'میذارن': 1,\n",
       "  'برا': 1,\n",
       "  'رباته،': 1,\n",
       "  'مثلا': 1,\n",
       "  'فلان': 2,\n",
       "  'چیزی': 1,\n",
       "  'دیدی،': 1,\n",
       "  'ری': 1,\n",
       "  'اکشن': 1,\n",
       "  'نشون': 1,\n",
       "  'بده،': 1,\n",
       "  'شبیه': 1,\n",
       "  'سازی': 1,\n",
       "  'کامل': 1,\n",
       "  'از': 1,\n",
       "  'انسان': 1,\n",
       "  'دیگه': 2,\n",
       "  'کلا': 1,\n",
       "  'وجود': 1,\n",
       "  'ادم': 1,\n",
       "  'هیچ': 1,\n",
       "  'ضرورتی': 1,\n",
       "  'نداره،': 1,\n",
       "  'هوشمند': 1,\n",
       "  'میان': 1,\n",
       "  'جای': 1,\n",
       "  'ادما🙈': 1,\n",
       "  'فک': 1,\n",
       "  'کنم': 1,\n",
       "  'بشر': 1,\n",
       "  'داره': 1,\n",
       "  'ته': 1,\n",
       "  'خط': 1,\n",
       "  'میرسه😂': 1},\n",
       " 'Ali Hejazi': {'سلام': 1,\n",
       "  'امشب': 3,\n",
       "  'وقت': 3,\n",
       "  'نشد': 1,\n",
       "  'چیزی': 1,\n",
       "  'بذارم.': 1,\n",
       "  'همون': 3,\n",
       "  'شنبه': 2,\n",
       "  'ادامه': 1,\n",
       "  'میدیم.': 1,\n",
       "  'هفته\\u200cی': 1,\n",
       "  'بعد': 5,\n",
       "  'چند': 2,\n",
       "  'جلسه': 4,\n",
       "  'میذارم.': 1,\n",
       "  'قربانت': 3,\n",
       "  'آره': 5,\n",
       "  'الان': 7,\n",
       "  'کلا': 3,\n",
       "  'پسورد': 1,\n",
       "  'رو': 10,\n",
       "  'از': 5,\n",
       "  'روش': 1,\n",
       "  'برداشتم.': 1,\n",
       "  'ببین': 1,\n",
       "  'کار': 3,\n",
       "  'می\\u200cکنه': 4,\n",
       "  'یا': 2,\n",
       "  'نه.': 1,\n",
       "  'اگه': 5,\n",
       "  'کسی': 5,\n",
       "  'جلسه\\u200cهای': 1,\n",
       "  'قبلی': 2,\n",
       "  'سوالی': 1,\n",
       "  'داشت': 3,\n",
       "  'هر': 6,\n",
       "  'مشکلی': 3,\n",
       "  'میشه': 5,\n",
       "  'هم': 6,\n",
       "  'یه': 4,\n",
       "  'گذاشت.': 1,\n",
       "  'خلاصه': 1,\n",
       "  'که': 9,\n",
       "  'بگه': 1,\n",
       "  'ست': 1,\n",
       "  'می\\u200cکنیم': 1,\n",
       "  'بچه\\u200cها': 5,\n",
       "  'لینک': 2,\n",
       "  'جلسه\\u200cها': 1,\n",
       "  'توی': 3,\n",
       "  'همین': 3,\n",
       "  'گوگل': 2,\n",
       "  'داک': 2,\n",
       "  'دفعه': 1,\n",
       "  'آپدیت': 1,\n",
       "  'می\\u200cکنم.': 1,\n",
       "  'جلسه\\u200cی': 7,\n",
       "  'اول': 2,\n",
       "  'لینوکس': 4,\n",
       "  'گذاشتم.': 1,\n",
       "  'ساعت': 7,\n",
       "  '۵': 6,\n",
       "  'و': 11,\n",
       "  'نیم': 4,\n",
       "  'فراموش': 2,\n",
       "  'نشه': 1,\n",
       "  'این': 2,\n",
       "  'لینک\\u200cها': 1,\n",
       "  'پین': 1,\n",
       "  'شدن': 1,\n",
       "  'هفتگی': 1,\n",
       "  'هستش.': 1,\n",
       "  'یعنی': 1,\n",
       "  'هفته': 2,\n",
       "  'دیگه': 1,\n",
       "  'جدید': 3,\n",
       "  'نمی\\u200cسازم': 1,\n",
       "  'اضافه': 2,\n",
       "  'شد.': 1,\n",
       "  '۵:۳۰': 1,\n",
       "  'یادتون': 3,\n",
       "  'نره.': 3,\n",
       "  'مهم': 1,\n",
       "  'هست': 2,\n",
       "  'چون': 2,\n",
       "  'تمرین': 1,\n",
       "  'روی': 2,\n",
       "  'همه\\u200cی': 3,\n",
       "  'چیزهاییه': 1,\n",
       "  'گفتیم.': 1,\n",
       "  'کلاس': 4,\n",
       "  'پایتون': 2,\n",
       "  'قربانت.': 1,\n",
       "  'Practice': 2,\n",
       "  'Session': 2,\n",
       "  '02': 1,\n",
       "  '05': 1,\n",
       "  'شدن.': 1,\n",
       "  'تا': 1,\n",
       "  'دقیقه\\u200cی': 1,\n",
       "  'دیگه.': 2,\n",
       "  'آره.': 3,\n",
       "  'در': 1,\n",
       "  'نهایت': 1,\n",
       "  'اینها': 1,\n",
       "  'ختم': 1,\n",
       "  'به': 1,\n",
       "  'تحریک': 1,\n",
       "  'نورون\\u200cهای': 1,\n",
       "  'مغز.': 1,\n",
       "  'بتونی': 1,\n",
       "  'اون': 2,\n",
       "  'تحریک\\u200cها': 1,\n",
       "  'با': 1,\n",
       "  'سیگنال\\u200cهای': 1,\n",
       "  'الکتریکی': 1,\n",
       "  'شبیه\\u200cسازی': 1,\n",
       "  'کنی،': 1,\n",
       "  'حس': 1,\n",
       "  'بویایی،': 1,\n",
       "  'لامسه،': 1,\n",
       "  'خواب': 1,\n",
       "  'اینا': 1,\n",
       "  'حل': 1,\n",
       "  'میشه.': 2,\n",
       "  'دقیقا.': 1,\n",
       "  'برای': 1,\n",
       "  'اونا': 1,\n",
       "  'خلقتشون': 1,\n",
       "  'توسط': 1,\n",
       "  'بشر': 1,\n",
       "  'مه\\u200cبانگ': 2,\n",
       "  'همش': 1,\n",
       "  'براشون': 1,\n",
       "  'سوال': 1,\n",
       "  'قبل': 1,\n",
       "  'چی': 2,\n",
       "  'بوده،': 1,\n",
       "  'چرا': 2,\n",
       "  'بوجود': 1,\n",
       "  'اومدن،': 1,\n",
       "  'اینکه': 1,\n",
       "  'مردن': 1,\n",
       "  'میشن': 1,\n",
       "  'سایر': 1,\n",
       "  'موارد': 1,\n",
       "  ':))': 5,\n",
       "  'ویروس': 2,\n",
       "  'کامپیوتری': 1,\n",
       "  'می\\u200cگیرن': 1,\n",
       "  'مریضی': 1,\n",
       "  'ما': 2,\n",
       "  'آنتی\\u200cویروس': 1,\n",
       "  'ورود': 1,\n",
       "  'نمی\\u200cکنه': 1,\n",
       "  'مثل': 1,\n",
       "  'کرونا.': 1,\n",
       "  'میگی': 1,\n",
       "  'جنتی': 1,\n",
       "  'خودمونه.': 1,\n",
       "  'آخ': 1,\n",
       "  'نمیگه': 1,\n",
       "  'هیچ': 1,\n",
       "  'نیم.': 1,\n",
       "  'Data': 2,\n",
       "  'Structure.': 1,\n",
       "  'امروز': 3,\n",
       "  'نشه.': 1,\n",
       "  'تمرینه': 1,\n",
       "  'یکم': 1,\n",
       "  'درس': 1,\n",
       "  'دادن.': 1,\n",
       "  'روز\\u200cهای': 1,\n",
       "  'جمعه': 1,\n",
       "  'جوین': 3,\n",
       "  'شین.': 1,\n",
       "  'هست.': 1,\n",
       "  'Object': 1,\n",
       "  'Oriented': 1,\n",
       "  'Programming': 1,\n",
       "  'میگم.': 1,\n",
       "  'گفتم': 1,\n",
       "  'خواست': 1,\n",
       "  'بیاد': 1,\n",
       "  'حتما.': 1,\n",
       "  'گذاشتم': 1,\n",
       "  'فکر': 1,\n",
       "  'کنم.': 1,\n",
       "  'مگه': 1,\n",
       "  'نیست؟': 1,\n",
       "  'داریم.': 1,\n",
       "  'درو': 1,\n",
       "  'باز': 1,\n",
       "  'می\\u200cکنم': 1,\n",
       "  'بشین.': 1,\n",
       "  'داره': 1,\n",
       "  'چیزی،': 1,\n",
       "  'کلاس\\u200cهای': 1,\n",
       "  'می\\u200cتونه': 1,\n",
       "  'بمونه': 1,\n",
       "  'حلش': 1,\n",
       "  'کنیم.': 1,\n",
       "  'حالا': 2,\n",
       "  'چه': 2,\n",
       "  'روز': 1,\n",
       "  'دیگه\\u200cای': 1,\n",
       "  'Structure': 1,\n",
       "  '۵:۳۰.': 1,\n",
       "  'محمد': 1,\n",
       "  'team': 1,\n",
       "  'leader': 1,\n",
       "  'من': 3,\n",
       "  'AltaML': 1,\n",
       "  'عه.': 1,\n",
       "  'باهاش': 1,\n",
       "  'میتینگ': 1,\n",
       "  'داشتم': 1,\n",
       "  'بحث': 1,\n",
       "  'کلاس\\u200cها': 2,\n",
       "  'پیش': 1,\n",
       "  'اومد،': 1,\n",
       "  'دوست': 1,\n",
       "  'ببینه': 1,\n",
       "  'احتمالا': 2,\n",
       "  'بیشتر': 1,\n",
       "  'کمک': 1,\n",
       "  'حتی.': 1,\n",
       "  'بهمون': 1,\n",
       "  'join': 1,\n",
       "  'سری': 1,\n",
       "  'پیام\\u200cهای': 1,\n",
       "  'پاک': 1,\n",
       "  'کردم': 1,\n",
       "  'راحت\\u200cتر': 1,\n",
       "  'بتونه': 1,\n",
       "  'پیدا': 1,\n",
       "  'کنه': 1,\n",
       "  'مطالب': 1,\n",
       "  '(گفتم': 1,\n",
       "  'بگم': 1,\n",
       "  'ناراحت': 1,\n",
       "  'نشه).': 1,\n",
       "  'شرکت': 1,\n",
       "  'زیاد': 1,\n",
       "  'پرزنت': 1,\n",
       "  'همیشه': 1,\n",
       "  'نیمه': 1,\n",
       "  'Python': 1,\n",
       "  'شو': 1},\n",
       " 'Mohsen': {'علی': 8,\n",
       "  'دستت': 4,\n",
       "  'درد': 1,\n",
       "  'نکنه': 1,\n",
       "  'میشه': 1,\n",
       "  'لینک': 3,\n",
       "  'شنیه': 1,\n",
       "  'قبل': 1,\n",
       "  'رو': 5,\n",
       "  'هم': 4,\n",
       "  'بذاری؟': 1,\n",
       "  'طلا': 3,\n",
       "  '👍👍': 1,\n",
       "  'دو': 4,\n",
       "  'ساعته': 1,\n",
       "  'ایشالا؟': 1,\n",
       "  'بله': 3,\n",
       "  'با': 2,\n",
       "  'تشکر': 1,\n",
       "  'از': 3,\n",
       "  'اقدام': 1,\n",
       "  'فوری': 1,\n",
       "  'پیمان': 1,\n",
       "  'یاد': 1,\n",
       "  'این': 1,\n",
       "  'افتادم:': 1,\n",
       "  'انکس': 1,\n",
       "  'که': 3,\n",
       "  'نداند': 1,\n",
       "  'و': 2,\n",
       "  'بداند': 1,\n",
       "  'نداد': 1,\n",
       "  'لنگان': 1,\n",
       "  'خرک': 1,\n",
       "  'خویش': 1,\n",
       "  'به': 2,\n",
       "  'مقصد': 1,\n",
       "  'برساند': 1,\n",
       "  '😂😂😂😂': 1,\n",
       "  'تا': 2,\n",
       "  'لینکی': 1,\n",
       "  'بالا': 1,\n",
       "  'هست': 1,\n",
       "  'نمیتونی': 1,\n",
       "  'ببینی؟': 1,\n",
       "  'الان': 1,\n",
       "  'بقیه': 1,\n",
       "  'واست': 1,\n",
       "  'میفرستم': 1,\n",
       "  'اره': 2,\n",
       "  'حواسم': 1,\n",
       "  'نبود': 1,\n",
       "  'اینه': 1,\n",
       "  'دیروز': 1,\n",
       "  'گذاشتی': 1,\n",
       "  'جان؟': 1,\n",
       "  'جون': 1,\n",
       "  'جلسه': 2,\n",
       "  'اخیر': 1,\n",
       "  'روهر': 1,\n",
       "  'زمان': 1,\n",
       "  'بذاری': 1,\n",
       "  'ازت': 1,\n",
       "  'بسیار': 1,\n",
       "  'ممنون': 2,\n",
       "  'میشم': 1,\n",
       "  '🙏🏻🙏🏻🙏🏻': 2,\n",
       "  '🙏🏻🙏🏻🙏🏻🙏🏻': 1,\n",
       "  'دین': 1,\n",
       "  'ایمون': 1,\n",
       "  'ما': 3,\n",
       "  'جماعت': 1,\n",
       "  'رعیت': 1,\n",
       "  'بازی': 1,\n",
       "  'نکن': 1,\n",
       "  '😂': 1,\n",
       "  '😂😂😂😂😂😂😂': 2,\n",
       "  'دهنت': 1,\n",
       "  'سرویس': 1,\n",
       "  'ترجمه': 1,\n",
       "  'مناسبیه': 1,\n",
       "  'بنظرم': 1,\n",
       "  'اتفاقا': 1,\n",
       "  'بانگ': 1,\n",
       "  'بزرگ': 1,\n",
       "  'نه': 1,\n",
       "  'دیگه': 1,\n",
       "  'نمیدونم': 1,\n",
       "  'البته': 1,\n",
       "  'مریضی': 1,\n",
       "  'لا': 1,\n",
       "  'علاج': 1,\n",
       "  'چی': 1,\n",
       "  'عارفه': 1,\n",
       "  'هر': 1,\n",
       "  'جیزی': 1,\n",
       "  'میتونه': 2,\n",
       "  'باشه': 2,\n",
       "  'رمز': 1,\n",
       "  'اسکی': 1,\n",
       "  '۱۲۸': 1,\n",
       "  'حروف': 2,\n",
       "  'شیفت': 3,\n",
       "  'میکنن': 1,\n",
       "  'یهو': 1,\n",
       "  'میشن': 1,\n",
       "  'مثلا': 1,\n",
       "  '($@؟!': 1,\n",
       "  'یعنی': 1,\n",
       "  'لزوما': 1,\n",
       "  'حرف': 1,\n",
       "  'نمی': 1,\n",
       "  'مونن': 1,\n",
       "  'بعد': 3,\n",
       "  'ببین': 1,\n",
       "  'پیام': 1,\n",
       "  'شده': 1,\n",
       "  'اسکی،': 1,\n",
       "  'کرده،': 1,\n",
       "  'برگشته': 1,\n",
       "  'دست': 2,\n",
       "  'رسیده': 1,\n",
       "  '😁': 1,\n",
       "  'خواهش': 1,\n",
       "  'میکنم': 2,\n",
       "  'جون\\u200c': 1,\n",
       "  'فیلم': 1,\n",
       "  'اخر': 1,\n",
       "  'اپلود': 1,\n",
       "  'میکنی؟': 1,\n",
       "  'باتشکر....': 1,\n",
       "  'Oop': 1,\n",
       "  'رودیشب': 1,\n",
       "  'ندیدم': 1,\n",
       "  'شایداشتباه': 1,\n",
       "  'منه': 1,\n",
       "  'بذار': 1,\n",
       "  'دوباره': 1,\n",
       "  'چک': 1,\n",
       "  '😊😊': 1,\n",
       "  'احتمالا': 1,\n",
       "  'محمد': 2,\n",
       "  'امروز': 1,\n",
       "  'کلاس': 1,\n",
       "  'نیست': 1,\n",
       "  'کدوم': 1,\n",
       "  'شرکتی؟': 1,\n",
       "  'بند': 1,\n",
       "  'کن': 1,\n",
       "  '🤣🤣': 1},\n",
       " 'Mahsa Taheri': {'بچه\\u200cهای': 1,\n",
       "  'این': 1,\n",
       "  'کلاس': 1,\n",
       "  'همگی': 1,\n",
       "  'درس': 1,\n",
       "  'خونن\\u200cها': 1,\n",
       "  '😁': 1,\n",
       "  'من': 1,\n",
       "  'الان': 1,\n",
       "  'دیدم': 1,\n",
       "  'اینو': 1,\n",
       "  '😭😭': 1},\n",
       " 'Amir Sajedian': {'نه': 1,\n",
       "  'آقا': 1,\n",
       "  'همون': 1,\n",
       "  'دو': 1,\n",
       "  'جلسه': 1,\n",
       "  'خوبه.': 1,\n",
       "  'عالی': 1,\n",
       "  '.': 1,\n",
       "  'یک': 1,\n",
       "  '🙌🙌🙌🙌': 1,\n",
       "  'علی': 1,\n",
       "  'جان': 1,\n",
       "  'دستت': 1,\n",
       "  'درد': 1,\n",
       "  'نکنه.': 1,\n",
       "  'من': 1,\n",
       "  'منتظرم': 1,\n",
       "  'این': 1,\n",
       "  'امتحانم': 1,\n",
       "  'تموم': 1,\n",
       "  'شد': 1,\n",
       "  'همه': 1,\n",
       "  'رو': 2,\n",
       "  'مرور': 1,\n",
       "  'کنم.': 1,\n",
       "  'واقعا': 1,\n",
       "  'زحمت': 1,\n",
       "  'کشیدی': 1,\n",
       "  'مریض': 1,\n",
       "  'هم': 2,\n",
       "  'نمی': 2,\n",
       "  'شن': 1,\n",
       "  '؟': 2,\n",
       "  'انتی': 1,\n",
       "  'ویروس': 2,\n",
       "  'نصب': 1,\n",
       "  'کنن': 1,\n",
       "  'که': 4,\n",
       "  'دیگه': 1,\n",
       "  'حله': 1,\n",
       "  '😂😂😂😂😂': 2,\n",
       "  'اصلا': 1,\n",
       "  'سیستم': 1,\n",
       "  'عاملشون': 1,\n",
       "  'لینوکس': 1,\n",
       "  'می': 5,\n",
       "  'بندن': 1,\n",
       "  'نشه': 1,\n",
       "  'راحت': 1,\n",
       "  'گرفت': 1,\n",
       "  'بعد': 1,\n",
       "  'اینا': 1,\n",
       "  '،': 1,\n",
       "  'دونن': 3,\n",
       "  'دونن؟': 1,\n",
       "  'یا': 1,\n",
       "  'از': 1,\n",
       "  'تو': 1,\n",
       "  'ربات': 2,\n",
       "  'ها': 1,\n",
       "  'مثلا': 1,\n",
       "  'تونیم': 1,\n",
       "  'ترامپ': 1,\n",
       "  'و': 3,\n",
       "  'احمدی': 2,\n",
       "  'نژاد': 1,\n",
       "  'اوباما': 1,\n",
       "  '...دربیاریم': 1,\n",
       "  '؟😂😂😂': 1,\n",
       "  'نژادی': 1,\n",
       "  'دوست': 1,\n",
       "  'دارم': 1,\n",
       "  'ببینم': 1},\n",
       " 'Farnoush Azour': {'👍🏼👍🏼': 1,\n",
       "  'یس': 2,\n",
       "  'اینجا': 1,\n",
       "  'کلیک': 1,\n",
       "  'کنین': 1,\n",
       "  'بچه': 1,\n",
       "  'ها': 1,\n",
       "  'سلام:)': 1,\n",
       "  '۵': 1,\n",
       "  'و': 1,\n",
       "  'نیم': 1,\n",
       "  'کلاسه؟': 1,\n",
       "  'اقا': 2,\n",
       "  'امروز': 1,\n",
       "  'دوشمیس': 1,\n",
       "  'دیگه؟': 1,\n",
       "  'کلاس': 1,\n",
       "  'داریم': 1,\n",
       "  'درسه؟': 1,\n",
       "  'من': 2,\n",
       "  'از': 1,\n",
       "  'وقتی': 1,\n",
       "  'کویید': 1,\n",
       "  'شده': 1,\n",
       "  'همواره': 1,\n",
       "  'با': 1,\n",
       "  'استرس': 1,\n",
       "  'اینکه': 1,\n",
       "  'کلاسامو': 1,\n",
       "  'یادم': 1,\n",
       "  'بره': 1,\n",
       "  'موجهم': 1,\n",
       "  'خب': 1,\n",
       "  'علی': 1,\n",
       "  'پشت': 1,\n",
       "  'درم:))': 1},\n",
       " 'Ali Naeim abadi': {'ممنون': 1},\n",
       " 'Arefe B': {'عالی': 2,\n",
       "  'استاد': 1,\n",
       "  'لینک': 2,\n",
       "  'کلاس': 2,\n",
       "  'رو': 3,\n",
       "  'هم': 1,\n",
       "  'لطفا': 1,\n",
       "  'شیر': 1,\n",
       "  'کن': 1,\n",
       "  'مرسی': 2,\n",
       "  'ممنون': 1,\n",
       "  'میفرستی': 1,\n",
       "  'علی': 1,\n",
       "  'جان': 1,\n",
       "  '👌': 1,\n",
       "  'من': 2,\n",
       "  'با': 1,\n",
       "  'سیستم': 1,\n",
       "  'دیگه': 2,\n",
       "  'وارد': 1,\n",
       "  'شدم': 1,\n",
       "  'ازم': 1,\n",
       "  'password': 1,\n",
       "  'میخواد': 1,\n",
       "  'اکی': 1,\n",
       "  'اخه': 1,\n",
       "  'اگه': 1,\n",
       "  'هرچی': 1,\n",
       "  'پس': 1,\n",
       "  'شیفت': 3,\n",
       "  'توی': 1,\n",
       "  'مثلا': 1,\n",
       "  '@': 1,\n",
       "  'به': 1,\n",
       "  'چه': 1,\n",
       "  'معناست؟': 1,\n",
       "  '🙄': 1,\n",
       "  'نمیشه': 1,\n",
       "  'روی': 1,\n",
       "  'حروف': 1,\n",
       "  'هست': 1,\n",
       "  'فکر': 1,\n",
       "  'کنم': 1,\n",
       "  'دیشب': 1,\n",
       "  'چرت': 1,\n",
       "  'میزدم': 1,\n",
       "  'داشت': 1,\n",
       "  'صورت': 1,\n",
       "  'مساله': 1,\n",
       "  'میگفت😆': 1,\n",
       "  'پیام': 1,\n",
       "  'اصلی': 1,\n",
       "  'اول': 1,\n",
       "  'داده': 1,\n",
       "  'شده': 2,\n",
       "  'بعد': 1,\n",
       "  'اسکی.': 1,\n",
       "  'درست': 2,\n",
       "  'فهمیدم': 1,\n",
       "  'اینو؟': 1,\n",
       "  'اهان': 1,\n",
       "  'خب': 1,\n",
       "  'این': 1,\n",
       "  'شدمرسی👌': 1},\n",
       " 'Sara Gh': {'دمت': 2,\n",
       "  'گرم': 2,\n",
       "  'استاد': 1,\n",
       "  'حجازی': 1,\n",
       "  'بچه': 2,\n",
       "  'ها': 2,\n",
       "  'جون': 1,\n",
       "  'این': 1,\n",
       "  'جلسه': 1,\n",
       "  'اول': 1,\n",
       "  'کلاس': 3,\n",
       "  'هستش': 1,\n",
       "  'علی👌': 1,\n",
       "  'من': 2,\n",
       "  'الان': 2,\n",
       "  'روش': 1,\n",
       "  'کلیک': 2,\n",
       "  'کردم': 1,\n",
       "  'access': 1,\n",
       "  'request': 1,\n",
       "  'نیاز': 1,\n",
       "  'داره': 1,\n",
       "  'اره': 1,\n",
       "  'درست': 1,\n",
       "  'شد.': 1,\n",
       "  'عالیییی👌👌': 1,\n",
       "  'مرسییی': 1,\n",
       "  'علی': 1,\n",
       "  'جان🙏🏻🙏🏻': 1,\n",
       "  'جون،': 1,\n",
       "  'برای': 1,\n",
       "  'هر': 1,\n",
       "  'کلاس،': 1,\n",
       "  'تاپیک': 2,\n",
       "  'خودش': 1,\n",
       "  'لینک': 1,\n",
       "  'زوم': 1,\n",
       "  'هستش.': 1,\n",
       "  'روی': 1,\n",
       "  'اون': 1,\n",
       "  'روز': 1,\n",
       "  'کنید.': 1,\n",
       "  'محمد': 1,\n",
       "  'ریاضی؟': 1,\n",
       "  'عالی': 1,\n",
       "  'برادر👌🏻👌🏻': 1,\n",
       "  'عههه': 1,\n",
       "  'دیدم': 1,\n",
       "  'اینو😅😅': 1},\n",
       " 'Arash': {'👍': 2,\n",
       "  'ممنون': 1,\n",
       "  'علی': 3,\n",
       "  'جان': 2,\n",
       "  'امروز': 1,\n",
       "  'کلاس': 1,\n",
       "  'هست؟': 1,\n",
       "  'لینک': 2,\n",
       "  'جلسات،': 1,\n",
       "  'زمانبندی': 1,\n",
       "  'و': 2,\n",
       "  'همه': 1,\n",
       "  'چی': 1,\n",
       "  'مرتب': 1,\n",
       "  'منظم': 1,\n",
       "  'ای': 1,\n",
       "  'ول': 1,\n",
       "  '💐': 1,\n",
       "  'زوم': 1,\n",
       "  'رو': 1,\n",
       "  'میسازی': 1,\n",
       "  'سلام': 1,\n",
       "  'محمد': 1,\n",
       "  'جان،': 1,\n",
       "  'خوشحالم': 1,\n",
       "  'اینجا': 1,\n",
       "  'میبینمت.': 1},\n",
       " 'Gazal': {'👌': 1, '999999': 1, 'قربانت': 1},\n",
       " 'Peyman T': {'سلام': 1,\n",
       "  'به': 2,\n",
       "  'همه\\u200cی': 1,\n",
       "  'علم\\u200cآموزان': 1,\n",
       "  'و': 3,\n",
       "  'دانشمندان': 1,\n",
       "  'دوستان': 1,\n",
       "  'لینک': 2,\n",
       "  'کلیه\\u200cی': 1,\n",
       "  'جلسات': 1,\n",
       "  'برگزار': 1,\n",
       "  'شده': 1,\n",
       "  'از': 2,\n",
       "  'ابتدا': 1,\n",
       "  'رو': 3,\n",
       "  'لطف': 1,\n",
       "  'می\\u200cکنید': 1,\n",
       "  'من': 2,\n",
       "  'بدید': 1,\n",
       "  'تا': 1,\n",
       "  'بلکه': 1,\n",
       "  'پشت': 1,\n",
       "  'لنگ\\u200cلنگ': 1,\n",
       "  'برسونم': 1,\n",
       "  'خودم': 1,\n",
       "  'رو؟': 1,\n",
       "  'ممنون': 1,\n",
       "  'واقعا': 1,\n",
       "  'همین': 1,\n",
       "  'شعر': 1,\n",
       "  'پس': 1,\n",
       "  'ذهنم': 1,\n",
       "  'بود': 1,\n",
       "  'این': 2,\n",
       "  'پیام': 1,\n",
       "  'نوشتم😁😂': 1,\n",
       "  'نوشته': 1,\n",
       "  'روز': 1,\n",
       "  'شنبه': 1,\n",
       "  'روزهای': 1,\n",
       "  'دیگر': 1,\n",
       "  'چه؟': 1,\n",
       "  'فقط': 1,\n",
       "  'میتینگه': 1,\n",
       "  'ریکوردینگ': 1,\n",
       "  'نیست': 1,\n",
       "  'مرسی': 1,\n",
       "  'جلسه\\u200cی': 1,\n",
       "  'اول': 1,\n",
       "  '(نصب': 1,\n",
       "  'نرم\\u200cافزارها': 1,\n",
       "  'فلان)': 1,\n",
       "  'دارید؟': 1},\n",
       " 'Machine Learning with Python': {'بچه\\u200cها': 1,\n",
       "  'لینک': 2,\n",
       "  'همه\\u200cی': 1,\n",
       "  'جلسه\\u200cها': 1,\n",
       "  'و': 3,\n",
       "  'تاریخ': 1,\n",
       "  'تاپیکشون': 1,\n",
       "  'رو': 1,\n",
       "  'گذاشتم': 1,\n",
       "  'توی': 2,\n",
       "  'این': 1,\n",
       "  'گوگل': 1,\n",
       "  'داک.': 1,\n",
       "  'یه': 1,\n",
       "  'channel': 1,\n",
       "  'وصل': 1,\n",
       "  'کردم': 1,\n",
       "  'به': 1,\n",
       "  'گروه': 1,\n",
       "  'که': 1,\n",
       "  'لینک\\u200cها': 1,\n",
       "  'پست\\u200cهای': 1,\n",
       "  'مهم': 1,\n",
       "  'پاک': 1,\n",
       "  'یا': 1,\n",
       "  'گم': 1,\n",
       "  'نشه.': 1,\n",
       "  'قربانت.': 1,\n",
       "  'فکر': 1,\n",
       "  'کنم': 1,\n",
       "  'الان': 1,\n",
       "  'درست': 1,\n",
       "  'شد.': 1,\n",
       "  'قبلش': 1,\n",
       "  'فقط': 1,\n",
       "  'با': 1,\n",
       "  'ایمیل': 1,\n",
       "  'آلبرتا': 1,\n",
       "  'میشد': 1,\n",
       "  'آره': 1,\n",
       "  'امروز': 1,\n",
       "  '۵:۳۰': 1,\n",
       "  'تا': 1,\n",
       "  '۷': 1,\n",
       "  'جلسه\\u200cی': 1,\n",
       "  'اول': 1,\n",
       "  'لینوکسه.': 1,\n",
       "  'هر': 1,\n",
       "  'جلسه': 1,\n",
       "  'پیام': 1,\n",
       "  'قبلی': 1,\n",
       "  'hyperlink': 1,\n",
       "  'شده.': 1},\n",
       " 'Hadi': {'دستت': 1, 'درد': 1, 'نکنه': 1, 'علی': 1, 'جان': 1},\n",
       " 'Amin': {'مهبانگ؟': 1,\n",
       "  '😂😂': 1,\n",
       "  'در': 1,\n",
       "  'مورد': 1,\n",
       "  'ریشه\\u200cی': 1,\n",
       "  'کلمه': 1,\n",
       "  'هم': 1,\n",
       "  'توضیح': 1,\n",
       "  'میدی': 1,\n",
       "  'استاد؟': 1,\n",
       "  '😂😂😂': 1,\n",
       "  'بانگ': 3,\n",
       "  'بیشتر': 1,\n",
       "  'بهش': 1,\n",
       "  'میاد': 1,\n",
       "  'خروس': 1,\n",
       "  'یا': 1,\n",
       "  'اذان': 1,\n",
       "  'باشه!': 1},\n",
       " 'M': {'دمت': 1,\n",
       "  'گرم': 1,\n",
       "  'بله': 1,\n",
       "  '👍': 1,\n",
       "  'امروز': 1,\n",
       "  'كلاس': 1,\n",
       "  '٥:٣٠': 1,\n",
       "  'شروع': 1,\n",
       "  'ميشه؟': 1,\n",
       "  'مرسي': 1},\n",
       " 'Adrian Kamyab': {'بنده': 1,\n",
       "  'هم': 1,\n",
       "  'خوشحال': 1,\n",
       "  'هستم': 2,\n",
       "  'ک': 1,\n",
       "  'تو': 1,\n",
       "  'جمع': 1,\n",
       "  'شما': 1,\n",
       "  'لینکش': 1,\n",
       "  'همینجاس؟': 1,\n",
       "  'لینک': 1,\n",
       "  'زومش؟': 1},\n",
       " 'Mostafa': {'علی': 1,\n",
       "  'تو': 1,\n",
       "  'شرکت': 2,\n",
       "  'AltaML': 1,\n",
       "  'کار': 1,\n",
       "  'میکنی؟': 1,\n",
       "  'یه': 3,\n",
       "  'مدت': 1,\n",
       "  'پیش': 2,\n",
       "  'مدل': 1,\n",
       "  'بینی': 1,\n",
       "  'واسه': 1,\n",
       "  'ما': 1,\n",
       "  'انجام': 1,\n",
       "  'دادن،': 1,\n",
       "  'تیک': 1,\n",
       "  'هفت': 1,\n",
       "  'هشت': 1,\n",
       "  'نفره': 1,\n",
       "  'اومدن': 1,\n",
       "  'پرزنت': 1,\n",
       "  'کردن': 1},\n",
       " 'Mohammad pmb': {'tooshim': 1,\n",
       "  'Oops,': 1,\n",
       "  'fek': 1,\n",
       "  'kardam': 1,\n",
       "  'emruz': 1,\n",
       "  'jomast': 1},\n",
       " 'Mohammad Riazi': {'سلام': 1,\n",
       "  'به': 2,\n",
       "  'همه': 1,\n",
       "  'دوستان،': 1,\n",
       "  'علی': 1,\n",
       "  'محبت': 1,\n",
       "  'داره': 1,\n",
       "  'و': 1,\n",
       "  'خودش': 1,\n",
       "  'استاد': 1,\n",
       "  'هست.': 2,\n",
       "  'من': 2,\n",
       "  'صرفا': 1,\n",
       "  'دوست': 1,\n",
       "  'داشتم': 1,\n",
       "  'کسب': 1,\n",
       "  'تجربه': 1,\n",
       "  'کنم.': 1,\n",
       "  'مطالبی': 1,\n",
       "  'رو': 2,\n",
       "  'که': 1,\n",
       "  'با': 1,\n",
       "  'کمک': 1,\n",
       "  'شما': 1,\n",
       "  'آماده': 1,\n",
       "  'کرده': 1,\n",
       "  'واقعا': 1,\n",
       "  'عالی': 1,\n",
       "  'ممنون': 2,\n",
       "  'از': 1,\n",
       "  'اینکه': 1,\n",
       "  'هم': 1,\n",
       "  'جمعتون': 1,\n",
       "  'اضافه': 1,\n",
       "  'کردین': 1,\n",
       "  '🌸': 2,\n",
       "  'بامید': 1,\n",
       "  'دیدار': 1,\n",
       "  'ارادت': 1,\n",
       "  'محسن': 1,\n",
       "  'جان': 2,\n",
       "  '😊': 1,\n",
       "  'سارا': 1,\n",
       "  'چقدر': 1,\n",
       "  'چهره': 1,\n",
       "  'های': 1,\n",
       "  'آشنایی': 1,\n",
       "  'داخل': 1,\n",
       "  'گروه': 1,\n",
       "  'هستن': 1,\n",
       "  '👌🏻': 1}}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step #3: Create `tf` (Term Frequency)\n",
    "\n",
    "> 1. Create a dictionary where words are keys and values are a list.\n",
    "> 2. Values are a list of corresponding documents frequencies.\n",
    "\n",
    "```python\n",
    "tf = {\n",
    "    word_1: [freq_doc_1, freq_doc_2, freq_doc_3, ..., freq_doc_n],\n",
    "    word_2: [freq_doc_1, freq_doc_2, freq_doc_3, ..., freq_doc_n],\n",
    "    word_3: [freq_doc_1, freq_doc_2, freq_doc_3, ..., freq_doc_n],\n",
    "    ...\n",
    "    word_n: [freq_doc_1, freq_doc_2, freq_doc_3, ..., freq_doc_n],\n",
    "}\n",
    "```\n",
    "\n",
    "| |doc_1|doc_2|...|doc_n|\n",
    "|--|--|--|--|--|\n",
    "|word_1|10|4|...|14|\n",
    "|word_2|8|11|...|4|\n",
    "|word_3|3|5|...|1|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 685/685 [00:00<00:00, 202931.08it/s]\n"
     ]
    }
   ],
   "source": [
    "for w in tqdm(vocab):\n",
    "    vector = []\n",
    "    for name, word_freq in tf_dict.items():\n",
    "        vector.append(word_freq.get(w, 0))\n",
    "        \n",
    "    tf[w] = vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step #4: Search\n",
    "\n",
    "Using dot product of vectors, ask a user to enter a query and find the most relevant documents.\n",
    "\n",
    "Example:\n",
    "- query: \"محسن نقش\"\n",
    "- output: `[doc_28, doc_4, ..., doc_19]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.argmax([i*j for i, j in zip(tf[\"هستم\"], tf[\"خروس\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fatemeh Modarres'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tf_dict.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a phrase:خروس هستم\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Enter a phrase:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
